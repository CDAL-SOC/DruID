{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df65a65d",
   "metadata": {},
   "source": [
    "Uses Morgan fingerprints, VAE repr for cell lines and patients, for cnv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12974b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from functools import cached_property\n",
    "\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "\n",
    "from sklearn.metrics import average_precision_score, ndcg_score, roc_auc_score\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datasets_drug_filtered import (\n",
    "    AggCategoricalAnnotatedCellLineDatasetFilteredByDrug,\n",
    "    AggCategoricalAnnotatedTcgaDatasetFilteredByDrug,\n",
    "    \n",
    ")\n",
    "\n",
    "from utils import get_kld_loss, get_zinb_loss\n",
    "\n",
    "from seaborn import scatterplot\n",
    "\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid randomness in DataLoaders - https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbad16",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import (\n",
    "    BaseDruidModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad465a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffnzinb import ffnzinb\n",
    "from vae import vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b51b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellLineEmbedder(nn.Module):\n",
    "    @cached_property\n",
    "    def device(self):\n",
    "        return torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint_base_path=\"../data/model_checkpoints\",\n",
    "    ):\n",
    "        super(CellLineEmbedder, self).__init__()\n",
    "        self.checkpoint_base_path = checkpoint_base_path\n",
    "\n",
    "        input_dim_vae = 324 * 3\n",
    "        k_list = [128, 16]\n",
    "        actf_list = [\"tanh\", \"tanh\"]\n",
    "        is_real = True\n",
    "\n",
    "        # The below modules are expected to be available in the scope where this module is instialized\n",
    "\n",
    "        self.vae_model1_raw_mutation = vae(input_dim_vae, k_list, actf_list, is_real)\n",
    "        self.vae_model1_raw_mutation = (\n",
    "            self.vae_model1_raw_mutation.cuda(device=self.device)\n",
    "            if self.device.type == \"cuda\"\n",
    "            else self.vae_model1_raw_mutation\n",
    "        )\n",
    "\n",
    "        self.vae_model2_raw_mutation = vae(input_dim_vae, k_list, actf_list, is_real)\n",
    "        self.vae_model2_raw_mutation = (\n",
    "            self.vae_model2_raw_mutation.cuda(device=self.device)\n",
    "            if self.device.type == \"cuda\"\n",
    "            else self.vae_model2_raw_mutation\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"CellLineEmbedder\"\n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        self.vae_model1_raw_mutation.load_state_dict(\n",
    "            torch.load(\n",
    "                f\"{self.checkpoint_base_path}/unsupervised_vae_model_cell_line_domain_cnv.pt\",\n",
    "                map_location=str(self.device),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.vae_model2_raw_mutation.load_state_dict(\n",
    "            torch.load(\n",
    "                f\"{self.checkpoint_base_path}/unsupervised_vae_model_other_domain_cnv.pt\",\n",
    "                map_location=str(self.device),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get cell line representation from annotated encoder\n",
    "        _, cell_line_emb, _, _ = self.vae_model1_raw_mutation(x)\n",
    "        return cell_line_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dca1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientEmbedder(nn.Module):\n",
    "    @cached_property\n",
    "    def device(self):\n",
    "        return torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint_base_path=\"../data/model_checkpoints\",\n",
    "    ):\n",
    "        super(PatientEmbedder, self).__init__()\n",
    "        self.checkpoint_base_path = checkpoint_base_path\n",
    "\n",
    "        input_dim_vae = 324 * 3\n",
    "        k_list = [128, 16]\n",
    "        actf_list = [\"tanh\", \"tanh\"]\n",
    "        is_real = True\n",
    "\n",
    "        # The below modules are expected to be available in the scope where this module is instialized\n",
    "\n",
    "        self.vae_model1_raw_mutation = vae(input_dim_vae, k_list, actf_list, is_real)\n",
    "        self.vae_model1_raw_mutation = (\n",
    "            self.vae_model1_raw_mutation.cuda(device=self.device)\n",
    "            if self.device.type == \"cuda\"\n",
    "            else self.vae_model1_raw_mutation\n",
    "        )\n",
    "\n",
    "        self.vae_model2_raw_mutation = vae(input_dim_vae, k_list, actf_list, is_real)\n",
    "        self.vae_model2_raw_mutation = (\n",
    "            self.vae_model2_raw_mutation.cuda(device=self.device)\n",
    "            if self.device.type == \"cuda\"\n",
    "            else self.vae_model2_raw_mutation\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"PatientEmbedder\"\n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        self.vae_model1_raw_mutation.load_state_dict(\n",
    "            torch.load(\n",
    "                f\"{self.checkpoint_base_path}/unsupervised_vae_model_cell_line_domain_cnv.pt\",\n",
    "                map_location=str(self.device),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.vae_model2_raw_mutation.load_state_dict(\n",
    "            torch.load(\n",
    "                f\"{self.checkpoint_base_path}/unsupervised_vae_model_other_domain_cnv.pt\",\n",
    "                map_location=str(self.device),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get patient representation from annotated encoder\n",
    "        _, patient_emb, _, _ = self.vae_model2_raw_mutation(x)\n",
    "        return patient_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40803f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names = ['DOCETAXEL', 'GEMCITABINE', 'CISPLATIN', 'PACLITAXEL', '5-FLUOROURACIL', 'CYCLOPHOSPHAMIDE']\n",
    "uniq_drug_names = np.unique(np.array(drug_names))\n",
    "drug_names_to_idx_map = dict(zip(uniq_drug_names, range(len(uniq_drug_names))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_drug_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fp = pd.read_csv(\"../data/processed/drug_morgan_fingerprints.csv\", index_col=0)\n",
    "drug_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ed0ab",
   "metadata": {},
   "source": [
    "### Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dataset_train = AggCategoricalAnnotatedCellLineDatasetFilteredByDrug(is_train=True, filter_for=\"tcga\", sample_id=sample_id)\n",
    "cl_dataset_train.y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_features = []\n",
    "cl_train_y = []\n",
    "for idx, row in cl_dataset_train.y_df.iterrows():\n",
    "    row_inp = []\n",
    "    row_inp.extend(cl_dataset_train.cnv.loc[row[\"depmap_id\"]].values)\n",
    "    row_inp.extend(drug_fp.loc[row[\"drug_name\"]].values)\n",
    "    row_inp.append(row[\"auc\"])\n",
    "    cl_train_y.append(row[\"auc\"])\n",
    "    cl_train_features.append(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dataset_test = AggCategoricalAnnotatedCellLineDatasetFilteredByDrug(is_train=False, filter_for=\"tcga\", sample_id=sample_id)\n",
    "cl_dataset_test.y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5208f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_test_features = []\n",
    "cl_test_y = []\n",
    "for idx, row in cl_dataset_test.y_df.iterrows():\n",
    "    row_inp = []\n",
    "    row_inp.extend(cl_dataset_test.cnv.loc[row[\"depmap_id\"]].values)\n",
    "    row_inp.extend(drug_fp.loc[row[\"drug_name\"]].values)\n",
    "    row_inp.append(row[\"auc\"])\n",
    "    cl_test_y.append(row[\"auc\"])\n",
    "    cl_test_features.append(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_inp) # 324 gene mutations + 2048 len fingerprint + 1 AUDRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_dataset_train = AggCategoricalAnnotatedTcgaDatasetFilteredByDrug(is_train=True, filter_for=\"tcga\", sample_id=sample_id)\n",
    "tcga_dataset_train.tcga_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_train_features = []\n",
    "tcga_train_y = []\n",
    "for idx, row in tcga_dataset_train.tcga_response.iterrows():\n",
    "    row_inp = []\n",
    "    row_inp.extend(tcga_dataset_train.cnv.loc[row[\"submitter_id\"]].values)\n",
    "    row_inp.extend(drug_fp.loc[row[\"drug_name\"]].values)\n",
    "    row_inp.append(row[\"response\"])\n",
    "    tcga_train_y.append(row[\"response\"])\n",
    "    tcga_train_features.append(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061987d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707babc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_dataset_test = AggCategoricalAnnotatedTcgaDatasetFilteredByDrug(is_train=False, filter_for=\"tcga\", sample_id=sample_id)\n",
    "tcga_dataset_test.tcga_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_test_features = []\n",
    "tcga_test_y = []\n",
    "for idx, row in tcga_dataset_test.tcga_response.iterrows():\n",
    "    row_inp = []\n",
    "    row_inp.extend(tcga_dataset_test.cnv.loc[row[\"submitter_id\"]].values)\n",
    "    row_inp.extend(drug_fp.loc[row[\"drug_name\"]].values)\n",
    "    row_inp.append(row[\"response\"])\n",
    "    tcga_test_y.append(row[\"response\"])\n",
    "    tcga_test_features.append(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DruID(nn.Module):\n",
    "    '''\n",
    "    Used for training 2 tasks - cell line-drug AUDRC prediction(regression) and patient-drug RECIST prediction(classification)\n",
    "    300 dimensional input for drugs\n",
    "    '''\n",
    "    def __init__(self,single=False):\n",
    "        super(DruID, self).__init__()\n",
    "        self.drug_embedder = self.fnn(2048, 64, 16, 8)\n",
    "        self.cell_line_embedder = CellLineEmbedder(checkpoint_base_path=f'/data/ajayago/druid/paper_intermediate//model_checkpoints/2B_druid_with_tcga_filtered_drug_sample{sample_id}/')\n",
    "        self.cell_line_embedder.load_model()\n",
    "        self.patient_embedder = PatientEmbedder(checkpoint_base_path=f'/data/ajayago/druid/paper_intermediate/model_checkpoints/2B_druid_with_tcga_filtered_drug_sample{sample_id}/')\n",
    "        self.patient_embedder.load_model()\n",
    "        self.recist_predictor = nn.Sequential(self.fnn(16, 64, 16, 1), ) # takes as input concatenated representation of cell line/patient and drug\n",
    "        self.audrc_predictor = nn.Sequential(self.fnn(16, 64, 16, 1), )#nn.Sigmoid())\n",
    "\n",
    "        self.AUDRC_specific = nn.ModuleDict({'embedder': self.cell_line_embedder,\n",
    "                                              'predictor': self.audrc_predictor})\n",
    "        self.RECIST_specific = nn.ModuleDict({'embedder': self.patient_embedder,\n",
    "                                                'predictor': self.recist_predictor})\n",
    "\n",
    "        self.name = 'DrugTRS - train AUDRC and RECIST together '\n",
    "        drug_names = ['DOCETAXEL', 'GEMCITABINE', 'CISPLATIN', 'PACLITAXEL', '5-FLUOROURACIL', 'CYCLOPHOSPHAMIDE']\n",
    "        uniq_drug_names = np.unique(np.array(drug_names))\n",
    "        self.device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        \n",
    "    def fnn(self, In, hidden1, hidden2, out):\n",
    "        return nn.Sequential(nn.Linear(In, hidden1), nn.ReLU(), #nn.BatchNorm1d(hidden1),\n",
    "                             nn.Linear(hidden1, hidden2), nn.ReLU(), #nn.BatchNorm1d(hidden2),\n",
    "                             nn.Linear(hidden2, out))\n",
    "\n",
    "    def forward(self,x1,x2): # x1 is Rad51, x2 is cell lines - each row is of the form [mutation 324, drug fp]\n",
    "        # input is of dim (batch_size, 325)\n",
    "        # drug input\n",
    "        patient_drug_input = x1[:, 324*3:].to(self.device, torch.float32)\n",
    "        cl_drug_input = x2[:, 324*3:].to(self.device, torch.float32)\n",
    "    \n",
    "        # mutation profile\n",
    "        patient_mut_input = torch.Tensor(x1[:,:324*3]).to(self.device, torch.float32)\n",
    "        cl_mut_input = torch.Tensor(x2[:,:324*3]).to(self.device, torch.float32)\n",
    "\n",
    "\n",
    "        patient_drug_emb = self.drug_embedder(patient_drug_input)\n",
    "        cl_drug_emb = self.drug_embedder(cl_drug_input)\n",
    "        \n",
    "        # mutation embedding\n",
    "        patient_mut_emb = self.patient_embedder(patient_mut_input)\n",
    "        cl_mut_emb = self.cell_line_embedder(cl_mut_input)\n",
    "        \n",
    "        # concat and pass through prediction heads\n",
    "        patient_drug_cat_emb = torch.cat((patient_mut_emb, patient_drug_emb), dim=1)\n",
    "        cl_drug_cat_emb = torch.cat((cl_mut_emb, cl_drug_emb), dim=1)\n",
    "        \n",
    "        recist_prediction = self.recist_predictor(patient_drug_cat_emb)\n",
    "        audrc_prediction = self.audrc_predictor(cl_drug_cat_emb)\n",
    "        \n",
    "        return recist_prediction, audrc_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2da188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "import yaml\n",
    "import wandb\n",
    "with open(f'../notebook/config/config_tcga_sample{sample_id}.yml', 'r') as f:\n",
    "    args = DotMap(yaml.safe_load(f))\n",
    "print(args)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_main_optim = 1e-5\n",
    "lr_cl_optim = 1e-6\n",
    "lr_patient_optim = 1e-4\n",
    "lr_drug_optim = 1e-4\n",
    "args.lr_main_optim = lr_main_optim\n",
    "args.lr_cl_optim = lr_cl_optim\n",
    "args.lr_patient_optim = lr_patient_optim\n",
    "args.lr_drug_optim = lr_drug_optim\n",
    "args.epochs = 500\n",
    "args.device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4849585",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "tasks = ['RECIST_prediction', 'AUDRC_prediction']  # prediction tasks; model consumes in this order; important\n",
    "\n",
    "# model\n",
    "model = eval(f'{args.model}()')\n",
    "device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device...')\n",
    "model = model.to(device)\n",
    "specific_submodels = {\n",
    "                      'RECIST_prediction': model.RECIST_specific,\n",
    "                      'AUDRC_prediction': model.AUDRC_specific\n",
    "                     }\n",
    "common_submodel = model.drug_embedder\n",
    "\n",
    "# optimization related\n",
    "batch_size = args.batch_size\n",
    "# optimizer_main = optim.Adam(model.parameters(), lr = lr_main_optim)\n",
    "optimizer_main = optim.Adam(list(model.audrc_predictor.parameters())+\n",
    "                            list(model.recist_predictor.parameters())\n",
    "                            , lr=lr_main_optim)  # , lr=1e-2)=\n",
    "optimizer_drug = optim.Adam(model.drug_embedder.parameters(), lr = lr_drug_optim)\n",
    "optimizer_cl = optim.Adam(model.cell_line_embedder.parameters(), lr=lr_cl_optim)\n",
    "optimizer_patient = optim.Adam(model.patient_embedder.parameters(), lr=lr_patient_optim)\n",
    "criteria = {\n",
    "            'RECIST_prediction': nn.BCEWithLogitsLoss(),\n",
    "            'AUDRC_prediction': nn.MSELoss(),\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb463654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, train_features):\n",
    "        self.train_features = train_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.train_features[idx][:-1]), self.train_features[idx][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_training_data = CustomDataset(cl_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_dataloader = DataLoader(cl_training_data, batch_size=batch_size, shuffle=True, generator=g, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31780317",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_test_data = CustomDataset(cl_test_features)\n",
    "cl_test_dataloader = DataLoader(cl_test_data, batch_size=batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_training_data = CustomDataset(tcga_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_train_dataloader = DataLoader(tcga_training_data, batch_size=batch_size, shuffle=True, generator=g, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28adca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_test_data = CustomDataset(tcga_test_features)\n",
    "tcga_test_dataloader = DataLoader(tcga_test_data, batch_size=batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f709c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = {\n",
    "    \"RECIST_prediction\": tcga_train_dataloader,\n",
    "    \"AUDRC_prediction\": cl_train_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = {\n",
    "    \"RECIST_prediction\": tcga_test_dataloader,\n",
    "    \"AUDRC_prediction\": cl_test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "                'RECIST_prediction': ['tcga'],\n",
    "                'AUDRC_prediction': ['ccle'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558280f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of iterations considering all datasets\n",
    "min_iterations = {task: [len(loader) * args.epochs for loader in loaders]\n",
    "                  for task, loaders in train_loaders.items()}\n",
    "max_iterations = max([max(iters) for iters in min_iterations.values()])\n",
    "\n",
    "# with open('models/cl_ids.json', 'r') as f:\n",
    "#     test_cl_ids = json.load(f)\n",
    "\n",
    "print(f'# of iterations to run = {max_iterations}')\n",
    "inv_preference = np.array(args.inv_preference)\n",
    "preference = 1.0 / inv_preference\n",
    "preference /= preference.sum()\n",
    "intra_preference = {task: np.ones(len(datasets[task])) / len(datasets[task]) for task in tasks}\n",
    "if args.moo == 'EPO':\n",
    "    epo_ = EPO(3, inv_preference)\n",
    "    epo_dt = EPO(3, np.array([1.,1.,1.]), eps=0.3)\n",
    "    epo_dr = EPO(2, np.array([1., 1.]))\n",
    "    epo_ds = EPO(2, np.array([1., 1.]))\n",
    "    epos = {task: ep for task, ep in zip(tasks, [epo_dt, epo_dr, epo_ds])}\n",
    "\n",
    "epochs_completed = {task: {ds: 0 for ds in task_datasets}\n",
    "                    for task, task_datasets in datasets.items()}\n",
    "train_iter_loaders = {task: [iter(loader) for loader in loaders]\n",
    "                      for task, loaders in train_loaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for i in range(max_iterations):\n",
    "    all_inputs = {task: [] for task in train_loaders}\n",
    "    all_targets = {task: [] for task in train_loaders}\n",
    "    for task, iter_loaders in train_loaders.items():\n",
    "        for inp, y in iter_loaders:\n",
    "            all_inputs[task].append(inp)\n",
    "            all_targets[task].append(y)\n",
    "    all_outputs = model(torch.cat(all_inputs[\"RECIST_prediction\"]), torch.cat(all_inputs[\"AUDRC_prediction\"]))\n",
    "    all_losses = {task: [criteria[task](all_outputs[tid], torch.cat(all_targets[task]).unsqueeze(1).to(device, torch.float32))\n",
    "                         ]\n",
    "                  for tid, (task, task_targets) in enumerate(all_targets.items())}\n",
    "    model.zero_grad()\n",
    "    optimizer_main.zero_grad()\n",
    "    optimizer_cl.zero_grad()\n",
    "    optimizer_patient.zero_grad()\n",
    "    optimizer_drug.zero_grad()\n",
    "    intra_coefs = {task: {ds: 0 for ds in datasets[task]} for task in tasks}\n",
    "    inter_coefs = {task: 0 for task in tasks}\n",
    "    if args.moo in ['LS', 'CS', 'ST']:\n",
    "        all_rel_losses = {task: [ds_loss * intra_preference[task][did] * preference[tid]\n",
    "                                 for did, ds_loss in enumerate(task_losses)]\n",
    "                          for tid, (task, task_losses) in enumerate(all_losses.items())}\n",
    "#         print(all_rel_losses)\n",
    "        if args.moo == 'LS':\n",
    "            total_loss = sum([sum(task_rel_losses)\n",
    "                              for task_rel_losses in all_rel_losses.values()])\n",
    "\n",
    "            for tid, task in enumerate(tasks):\n",
    "                inter_coefs[task] = preference[tid]\n",
    "                for did, ds in enumerate(datasets[task]):\n",
    "                    intra_coefs[task][ds] = intra_preference[task][did]\n",
    "        elif args.moo == 'CS':\n",
    "            total_loss = max([max(task_rel_losses)\n",
    "                              for task_rel_losses in all_rel_losses.values()])\n",
    "#             total_loss = max(all_rel_losses[\"RECIST_prediction\"]) # for single task\n",
    "            print(total_loss)\n",
    "            max_tid, max_rel_loss = None, -1\n",
    "            for tid, (task, task_rel_losses) in enumerate(all_rel_losses.items()):\n",
    "                max_did = max(range(len(task_rel_losses)), key=lambda lid: task_rel_losses[lid])\n",
    "                intra_coefs[task][datasets[task][max_did]] = intra_preference[task][max_did]\n",
    "                if task_rel_losses[max_did] > max_rel_loss:\n",
    "                    max_rel_loss = task_rel_losses[max_did]\n",
    "                    max_tid = tid\n",
    "            inter_coefs[tasks[max_tid]] = preference[max_tid]\n",
    "        else:\n",
    "            st_id = np.argmax(preference)\n",
    "            total_loss = sum(all_rel_losses[tasks[st_id]]) / preference[st_id]\n",
    "\n",
    "            inter_coefs[tasks[st_id]] = 1\n",
    "            for task in tasks:\n",
    "                for did, ds in enumerate(datasets[task]):\n",
    "                    intra_coefs[task][ds] = intra_preference[task][did]\n",
    "        total_loss.backward()\n",
    "    elif args.moo == 'EPO':\n",
    "        n_tasks = len(tasks)\n",
    "        shared_grads = [[] for _ in range(n_tasks)]  # NOTE: DO NOT USE [[]] * n_tasks.\n",
    "        apparent_losses = np.zeros(n_tasks)\n",
    "        for tid, (task, task_losses) in enumerate(all_losses.items()):\n",
    "            n_ds = len(task_losses)  # number of datasets in the task\n",
    "            specific_submodel = specific_submodels[task]\n",
    "            specific_submodel_grads = [[] for _ in range(n_ds)]\n",
    "            common_submodel_grads = [[] for _ in range(n_ds)]\n",
    "            for did, ds_loss in enumerate(task_losses):\n",
    "                ds_loss.backward()\n",
    "                for param in specific_submodel.parameters():\n",
    "                    specific_submodel_grads[did].append(param.grad.clone())\n",
    "                for param in common_submodel.parameters():\n",
    "                    common_submodel_grads[did].append(param.grad.clone())\n",
    "                specific_submodel.zero_grad()\n",
    "                common_submodel.zero_grad()\n",
    "            GG = torch.zeros(n_ds, n_ds)\n",
    "            for grads in [specific_submodel_grads, common_submodel_grads]:\n",
    "                for j in range(n_ds):\n",
    "                    for k in range(j, n_ds):\n",
    "                        Gj_dot_Gk = sum([gj.flatten().dot(gk.flatten())\n",
    "                                         for gj, gk in zip(grads[j], grads[k])]).cpu()\n",
    "                        GG[j, k] += Gj_dot_Gk\n",
    "                        GG[k, j] += Gj_dot_Gk\n",
    "\n",
    "            l = np.array([ds_loss.item() for ds_loss in task_losses], dtype=np.double)\n",
    "            print('intra-task epo:', task)\n",
    "            beta = epos[task].get_beta(l, GG.numpy().astype(np.double))\n",
    "            for pid, param in enumerate(specific_submodel.parameters()):\n",
    "                param.grad = sum([beta[j] * specific_submodel_grads[j][pid]\n",
    "                                  for j in range(n_ds)])\n",
    "\n",
    "            for pid, _ in enumerate(common_submodel.parameters()):\n",
    "                shared_grads[tid].append(sum([beta[j] * common_submodel_grads[j][pid]\n",
    "                                              for j in range(n_ds)]))\n",
    "            apparent_losses[tid] = l.dot(beta)\n",
    "\n",
    "            for did, ds in enumerate(datasets[task]):\n",
    "                intra_coefs[task][ds] = beta[did]\n",
    "\n",
    "        GG = torch.zeros(n_tasks, n_tasks)\n",
    "        for j in range(n_tasks):\n",
    "            for k in range(j, n_tasks):\n",
    "                GG[j, k] = sum([gj.flatten().dot(gk.flatten())\n",
    "                                for gj, gk in zip(shared_grads[j], shared_grads[k])])\n",
    "                GG[k, j] = GG[j, k]\n",
    "        print('inter-task epo')\n",
    "        beta = epo_.get_beta(apparent_losses, GG.numpy().astype(np.double))\n",
    "        for pid, param in enumerate(common_submodel.parameters()):\n",
    "            param.grad = sum([beta[j] * shared_grads[j][pid]\n",
    "                              for j in range(n_tasks)])\n",
    "\n",
    "        for tid, task in enumerate(tasks):\n",
    "            for param in specific_submodels[task].parameters():\n",
    "                param.grad *= beta[tid]\n",
    "\n",
    "        for tid, task in enumerate(tasks):\n",
    "            inter_coefs[task] = beta[tid]\n",
    "    else:\n",
    "        raise NotImplementedError('Choose an moo method')\n",
    "\n",
    "    optimizer_main.step()\n",
    "    if i > 10:\n",
    "        optimizer_cl.step()\n",
    "        optimizer_patient.step()\n",
    "        optimizer_drug.step()\n",
    "    log_losses = {task: {ds: loss.item() for ds, loss in zip(datasets[task], all_losses[task])}\n",
    "                  for task in tasks}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e72dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_outputs[0]:\n",
    "    print(i[0].cpu().detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735f6d6",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_preds = []\n",
    "for idx, (inp, y) in enumerate(tcga_test_dataloader):\n",
    "    # drug input\n",
    "    patient_drug_input = inp[:, 324*3:].to(device, torch.float32)\n",
    "    \n",
    "    # mutation profile\n",
    "    patient_mut_input = torch.Tensor(inp[:,:324*3]).to(model.device, torch.float32)\n",
    "\n",
    "    # drug embedding\n",
    "    patient_drug_emb = model.drug_embedder(patient_drug_input)\n",
    "\n",
    "    # mutation embedding\n",
    "    patient_mut_emb = model.patient_embedder(patient_mut_input)\n",
    "\n",
    "    # concat and pass through prediction heads\n",
    "    patient_drug_cat_emb = torch.cat((patient_mut_emb, patient_drug_emb), dim=1)\n",
    "\n",
    "    recist_prediction = model.recist_predictor(patient_drug_cat_emb)\n",
    "    y_preds.extend(list(recist_prediction.flatten().detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tcga_dataset_test.tcga_response\n",
    "y_pred = tcga_dataset_test.tcga_response.copy()\n",
    "y_pred[\"response\"] = y_preds\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_pivotted = y_pred.pivot_table(\n",
    "                \"response\", \"submitter_id\", \"drug_name\"\n",
    "            )\n",
    "y_pred_pivotted = y_pred_pivotted.fillna(0) # in case there are NaNs\n",
    "dict_idx_drug = pd.DataFrame(y_pred_pivotted.columns).to_dict()[\"drug_name\"]\n",
    "dict_id_drug = {}\n",
    "\n",
    "for patient_id, predictions in y_pred_pivotted.iterrows():\n",
    "\n",
    "    cur_pred_scores = predictions.values\n",
    "    cur_recom_drug_idx = np.argsort(cur_pred_scores)[:-11:-1]\n",
    "    #\n",
    "    dict_recom_drug = {}\n",
    "    for idx, cur_idx in enumerate(cur_recom_drug_idx):\n",
    "        dict_recom_drug[\n",
    "            dict_idx_drug[cur_idx]\n",
    "        ] = f\"{cur_pred_scores[cur_idx]} ({idx+1})\"\n",
    "    #\n",
    "    dict_id_drug[patient_id] = dict_recom_drug\n",
    "\n",
    "predictions_display_tcga = pd.DataFrame.from_dict(dict_id_drug)\n",
    "\n",
    "na_mask = y_pred.response.isna()\n",
    "if na_mask.sum():\n",
    "    print(\n",
    "        f\"Found {na_mask.sum()} rows with invalid response values\"\n",
    "    )\n",
    "    y_pred = y_pred[~na_mask]\n",
    "    y_true = y_true.loc[~(na_mask.values)]\n",
    "na_mask = y_true.response.isna()\n",
    "y_true = y_true[~na_mask]\n",
    "y_pred = y_pred[~na_mask]\n",
    "print(y_pred.shape)\n",
    "y_pred.head()\n",
    "y_combined = y_pred.merge(y_true, on=[\"submitter_id\", \"drug_name\"])\n",
    "\n",
    "from sklearn.metrics import average_precision_score, ndcg_score, roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "drugs_with_enough_support = [\"CISPLATIN\", \"PACLITAXEL\", \"5-FLUOROURACIL\"]\n",
    "\n",
    "for drug_name in drugs_with_enough_support:\n",
    "    try:\n",
    "        roc = roc_auc_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            y_pred[y_pred.drug_name == drug_name].response.values,\n",
    "            average=\"micro\",\n",
    "        )\n",
    "        aupr = average_precision_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            y_pred[y_pred.drug_name == drug_name].response.values,\n",
    "            average=\"micro\",\n",
    "        )\n",
    "        # Choosing the right threshold for F1, accuracy and precision calculation from ref: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            y_pred[y_pred.drug_name == drug_name].response.values,\n",
    "        )\n",
    "        J = tpr - fpr\n",
    "        ix = argmax(J)\n",
    "        best_thresh = thresholds[ix]\n",
    "        \n",
    "        f1 = f1_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            (y_pred[y_pred.drug_name == drug_name].response.values > best_thresh).astype(int),\n",
    "        )\n",
    "        acc_score = accuracy_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            (y_pred[y_pred.drug_name == drug_name].response.values > best_thresh).astype(int),\n",
    "        )\n",
    "        prec_score = precision_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            (y_pred[y_pred.drug_name == drug_name].response.values > best_thresh).astype(int),\n",
    "        )\n",
    "        rec_score = recall_score(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            (y_pred[y_pred.drug_name == drug_name].response.values > best_thresh).astype(int),\n",
    "        )\n",
    "        spearman_stats = stats.spearmanr(\n",
    "            y_true[y_true.drug_name == drug_name].response.values,\n",
    "            y_pred[y_pred.drug_name == drug_name].response.values,\n",
    "        )\n",
    "        mw_stats = stats.mannwhitneyu(\n",
    "            y_combined[\n",
    "                (y_combined.drug_name == drug_name) & (y_combined.response_y == 0)\n",
    "            ].response_x.values,\n",
    "            y_combined[\n",
    "                (y_combined.drug_name == drug_name) & (y_combined.response_y == 1)\n",
    "            ].response_x.values,\n",
    "            alternative=\"greater\",\n",
    "        )\n",
    "        denominator = (\n",
    "            y_combined[\n",
    "                (y_combined.drug_name == drug_name) & (y_combined.response_y == 0)\n",
    "            ].shape[0]\n",
    "            * y_combined[\n",
    "                (y_combined.drug_name == drug_name) & (y_combined.response_y == 1)\n",
    "            ].shape[0]\n",
    "        )\n",
    "        print(f\"AUROC for {drug_name}: {roc}\")\n",
    "        print(f\"AUPR for {drug_name}: {aupr}\")\n",
    "        print(f\"F1 for {drug_name}: {f1}\")\n",
    "        print(f\"Accuracy Score for {drug_name}: {acc_score}\")\n",
    "        print(f\"Precision Score for {drug_name}: {prec_score}\")\n",
    "        print(f\"Recall Score for {drug_name}: {rec_score}\")\n",
    "        print(\n",
    "            f\"Spearman for {drug_name}: {round(spearman_stats.correlation, 4)} (p-val: {round(spearman_stats.pvalue, 4)})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Mann-Whitney for {drug_name}: {round(mw_stats.statistic/denominator, 4)} (p-val: {round(mw_stats.pvalue, 4)})\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {drug_name} - {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aec118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "base2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
